"""
YouTube Analyzer - Utility Functions
–û–±—â–∏–µ —É—Ç–∏–ª–∏—Ç—ã –∏ –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
"""
import re
import json
import hashlib
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional, Union
from pathlib import Path
import unicodedata
import urllib.parse

class Utils:
    """–ö–ª–∞—Å—Å —Å —É—Ç–∏–ª–∏—Ç–∞—Ä–Ω—ã–º–∏ —Ñ—É–Ω–∫—Ü–∏—è–º–∏"""
    
    @staticmethod
    def format_number(num: Union[int, float, str]) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —á–∏—Å–µ–ª –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        try:
            num = float(num) if num else 0
            if num >= 1000000000:
                return f"{num / 1000000000:.1f}B"
            elif num >= 1000000:
                return f"{num / 1000000:.1f}M"
            elif num >= 1000:
                return f"{num / 1000:.1f}K"
            else:
                return str(int(num))
        except (ValueError, TypeError):
            return "0"
    
    @staticmethod
    def format_duration(duration: str) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–∑ ISO 8601 –≤ —á–∏—Ç–∞–µ–º—ã–π –≤–∏–¥"""
        if not duration:
            return "0:00"
        
        # –ü–∞—Ä—Å–∏–Ω–≥ ISO 8601 (PT1H2M3S -> 1:02:03)
        match = re.match(r'PT(?:(\d+)H)?(?:(\d+)M)?(?:(\d+)S)?', duration)
        if not match:
            return duration
        
        hours = int(match.group(1) or 0)
        minutes = int(match.group(2) or 0)
        seconds = int(match.group(3) or 0)
        
        if hours > 0:
            return f"{hours}:{minutes:02d}:{seconds:02d}"
        else:
            return f"{minutes}:{seconds:02d}"
    
    @staticmethod
    def parse_duration_to_seconds(duration: str) -> int:
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤ —Å–µ–∫—É–Ω–¥—ã"""
        if not duration:
            return 0
        
        match = re.match(r'PT(?:(\d+)H)?(?:(\d+)M)?(?:(\d+)S)?', duration)
        if not match:
            return 0
        
        hours = int(match.group(1) or 0)
        minutes = int(match.group(2) or 0)
        seconds = int(match.group(3) or 0)
        
        return hours * 3600 + minutes * 60 + seconds
    
    @staticmethod
    def format_date(date_str: str, short: bool = False) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞—Ç—ã"""
        if not date_str:
            return "-"
        
        try:
            # –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –¥–∞—Ç—ã
            date_formats = [
                "%Y-%m-%dT%H:%M:%SZ",
                "%Y-%m-%dT%H:%M:%S.%fZ",
                "%Y-%m-%d %H:%M:%S",
                "%Y-%m-%d"
            ]
            
            parsed_date = None
            for fmt in date_formats:
                try:
                    parsed_date = datetime.strptime(date_str, fmt)
                    break
                except ValueError:
                    continue
            
            if not parsed_date:
                # –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å ISO format
                parsed_date = datetime.fromisoformat(date_str.replace('Z', '+00:00'))
            
            if short:
                return parsed_date.strftime("%d.%m.%Y")
            else:
                return parsed_date.strftime("%d.%m.%Y %H:%M")
                
        except Exception:
            return date_str
    
    @staticmethod
    def calculate_engagement_rate(views: int, likes: int, comments: int) -> float:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –≤–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç–∏"""
        if views == 0:
            return 0.0
        return round(((likes + comments) / views) * 100, 2)
    
    @staticmethod
    def calculate_like_ratio(views: int, likes: int) -> float:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –ª–∞–π–∫–æ–≤"""
        if views == 0:
            return 0.0
        return round((likes / views) * 100, 2)
    
    @staticmethod
    def calculate_comment_ratio(views: int, comments: int) -> float:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤"""
        if views == 0:
            return 0.0
        return round((comments / views) * 100, 2)
    
    @staticmethod
    def clean_text(text: str) -> str:
        """–û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤"""
        if not text:
            return ""
        
        # –£–±—Ä–∞—Ç—å –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
        text = ' '.join(text.split())
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è Unicode
        text = unicodedata.normalize('NFKC', text)
        
        return text.strip()
    
    @staticmethod
    def extract_video_id_from_url(url: str) -> Optional[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ ID –≤–∏–¥–µ–æ –∏–∑ YouTube URL"""
        if not url:
            return None
        
        patterns = [
            r'(?:youtube\.com/watch\?v=|youtu\.be/)([a-zA-Z0-9_-]{11})',
            r'youtube\.com/embed/([a-zA-Z0-9_-]{11})',
            r'youtube\.com/v/([a-zA-Z0-9_-]{11})'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, url)
            if match:
                return match.group(1)
        
        # –ï—Å–ª–∏ —ç—Ç–æ —É–∂–µ ID
        if re.match(r'^[a-zA-Z0-9_-]{11}$', url):
            return url
        
        return None
    
    @staticmethod
    def extract_channel_id_from_url(url: str) -> Optional[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ ID –∫–∞–Ω–∞–ª–∞ –∏–∑ YouTube URL"""
        if not url:
            return None
        
        patterns = [
            r'youtube\.com/channel/([a-zA-Z0-9_-]+)',
            r'youtube\.com/c/([a-zA-Z0-9_-]+)',
            r'youtube\.com/user/([a-zA-Z0-9_-]+)',
            r'youtube\.com/@([a-zA-Z0-9_-]+)'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, url)
            if match:
                return match.group(1)
        
        return None
    
    @staticmethod
    def has_emoji(text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —ç–º–æ–¥–∑–∏ –≤ —Ç–µ–∫—Å—Ç–µ"""
        if not text:
            return False
        
        # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ —Å–∏–º–≤–æ–ª–æ–≤ –≤–Ω–µ ASCII
        return any(ord(char) > 127 for char in text)
    
    @staticmethod
    def count_links(text: str) -> int:
        """–ü–æ–¥—Å—á–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å—Å—ã–ª–æ–∫ –≤ —Ç–µ–∫—Å—Ç–µ"""
        if not text:
            return 0
        
        # –ü–æ–∏—Å–∫ HTTP/HTTPS —Å—Å—ã–ª–æ–∫
        http_links = len(re.findall(r'https?://\S+', text))
        
        # –ü–æ–∏—Å–∫ www —Å—Å—ã–ª–æ–∫
        www_links = len(re.findall(r'www\.\S+', text))
        
        return http_links + www_links
    
    @staticmethod
    def extract_keywords(text: str, top_n: int = 5) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        if not text:
            return []
        
        # –ü—Ä–æ—Å—Ç–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–ª–æ–≤ (–º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å —Å –ø–æ–º–æ—â—å—é TF-IDF)
        words = re.findall(r'\b[–∞-—è–ê-–Øa-zA-Z]+\b', text.lower())
        
        # –°—Ç–æ–ø-—Å–ª–æ–≤–∞
        stop_words = {
            '–∏', '–≤', '–≤–æ', '–Ω–µ', '—á—Ç–æ', '–æ–Ω', '–Ω–∞', '—è', '—Å', '—Å–æ', '–∫–∞–∫', '–∞', '—Ç–æ', '–≤—Å–µ', '–æ–Ω–∞', '—Ç–∞–∫',
            '–µ–≥–æ', '–Ω–æ', '–¥–∞', '—Ç—ã', '–∫', '—É', '–∂–µ', '–≤—ã', '–∑–∞', '–±—ã', '–ø–æ', '—Ç–æ–ª—å–∫–æ', '–µ–µ', '–º–Ω–µ', '–±—ã–ª–æ',
            '–≤–æ—Ç', '–æ—Ç', '–º–µ–Ω—è', '–µ—â–µ', '–Ω–µ—Ç', '–æ', '–∏–∑', '–µ–º—É', '—Ç–µ–ø–µ—Ä—å', '–∫–æ–≥–¥–∞', '–¥–∞–∂–µ', '–Ω—É', '–≤–¥—Ä—É–≥',
            '–ª–∏', '–µ—Å–ª–∏', '—É–∂–µ', '–∏–ª–∏', '–Ω–∏', '–±—ã—Ç—å', '–±—ã–ª', '–Ω–µ–≥–æ', '–¥–æ', '–≤–∞—Å', '–Ω–∏–±—É–¥—å', '–æ–ø—è—Ç—å', '—É–∂',
            'the', 'is', 'at', 'which', 'on', 'a', 'an', 'as', 'are', 'been', 'be', 'have', 'has', 'had',
            'i', 'it', 'its', 'of', 'that', 'to', 'was', 'will', 'with', 'what', 'when', 'where', 'who',
            'for', 'from', 'up', 'about', 'into', 'through', 'during', 'before', 'after', 'above', 'below'
        }
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏ –ø–æ–¥—Å—á–µ—Ç
        filtered_words = [word for word in words if word not in stop_words and len(word) > 3]
        
        from collections import Counter
        word_counts = Counter(filtered_words)
        
        return [word for word, _ in word_counts.most_common(top_n)]
    
    @staticmethod
    def generate_hash(text: str) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ö–µ—à–∞ –¥–ª—è —Ç–µ–∫—Å—Ç–∞"""
        if not text:
            return ""
        return hashlib.md5(text.encode('utf-8')).hexdigest()
    
    @staticmethod
    def validate_youtube_api_key(api_key: str) -> bool:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è YouTube API –∫–ª—é—á–∞"""
        if not api_key or api_key in ['YOUR_API_KEY_HERE', '***', '']:
            return False
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª–∏–Ω—ã (–æ–±—ã—á–Ω–æ 39 —Å–∏–º–≤–æ–ª–æ–≤)
        if len(api_key) < 30:
            return False
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ (—Ç–æ–ª—å–∫–æ –±—É–∫–≤—ã, —Ü–∏—Ñ—Ä—ã, –¥–µ—Ñ–∏—Å—ã, –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è)
        if not re.match(r'^[a-zA-Z0-9_-]+$', api_key):
            return False
        
        return True
    
    @staticmethod
    def safe_filename(filename: str) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞"""
        # –£–±—Ä–∞—Ç—å –æ–ø–∞—Å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
        safe_name = re.sub(r'[<>:"/\\|?*]', '_', filename)
        
        # –û–≥—Ä–∞–Ω–∏—á–∏—Ç—å –¥–ª–∏–Ω—É
        if len(safe_name) > 100:
            name, ext = safe_name.rsplit('.', 1) if '.' in safe_name else (safe_name, '')
            safe_name = name[:95] + ('.' + ext if ext else '')
        
        return safe_name
    
    @staticmethod
    def parse_json_safely(json_str: str, default=None) -> Any:
        """–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ JSON"""
        if not json_str:
            return default
        
        try:
            return json.loads(json_str)
        except (json.JSONDecodeError, TypeError):
            return default
    
    @staticmethod
    def create_video_url(video_id: str) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ URL –≤–∏–¥–µ–æ"""
        return f"https://youtube.com/watch?v={video_id}"
    
    @staticmethod
    def create_channel_url(channel_id: str) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ URL –∫–∞–Ω–∞–ª–∞"""
        return f"https://youtube.com/channel/{channel_id}"
    
    @staticmethod
    def time_ago(date_str: str) -> str:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞–∑–∞–¥"""
        if not date_str:
            return "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
        
        try:
            date = datetime.fromisoformat(date_str.replace('Z', '+00:00'))
            now = datetime.now(date.tzinfo)
            diff = now - date
            
            if diff.days > 365:
                return f"{diff.days // 365} –ª–µ—Ç –Ω–∞–∑–∞–¥"
            elif diff.days > 30:
                return f"{diff.days // 30} –º–µ—Å—è—Ü–µ–≤ –Ω–∞–∑–∞–¥"
            elif diff.days > 0:
                return f"{diff.days} –¥–Ω–µ–π –Ω–∞–∑–∞–¥"
            elif diff.seconds > 3600:
                return f"{diff.seconds // 3600} —á–∞—Å–æ–≤ –Ω–∞–∑–∞–¥"
            elif diff.seconds > 60:
                return f"{diff.seconds // 60} –º–∏–Ω—É—Ç –Ω–∞–∑–∞–¥"
            else:
                return "—Ç–æ–ª—å–∫–æ —á—Ç–æ"
                
        except Exception:
            return "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"

class FileUtils:
    """–£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ñ–∞–π–ª–∞–º–∏"""
    
    @staticmethod
    def ensure_directory(path: Union[str, Path]) -> Path:
        """–°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç"""
        path = Path(path)
        path.mkdir(parents=True, exist_ok=True)
        return path
    
    @staticmethod
    def get_file_size(file_path: Union[str, Path]) -> int:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞"""
        try:
            return Path(file_path).stat().st_size
        except OSError:
            return 0
    
    @staticmethod
    def clean_temp_files(temp_dir: Union[str, Path], max_age_hours: int = 24):
        """–û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ —Å—Ç–∞—Ä—à–µ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏"""
        temp_dir = Path(temp_dir)
        if not temp_dir.exists():
            return
        
        cutoff_time = datetime.now() - timedelta(hours=max_age_hours)
        
        for file_path in temp_dir.glob('*'):
            try:
                if file_path.is_file():
                    file_time = datetime.fromtimestamp(file_path.stat().st_mtime)
                    if file_time < cutoff_time:
                        file_path.unlink()
                        print(f"üóëÔ∏è  –£–¥–∞–ª–µ–Ω –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {file_path.name}")
            except OSError:
                continue

class ValidationUtils:
    """–£—Ç–∏–ª–∏—Ç—ã –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö"""
    
    @staticmethod
    def is_valid_video_id(video_id: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ YouTube video ID"""
        if not video_id:
            return False
        return bool(re.match(r'^[a-zA-Z0-9_-]{11}$', video_id))
    
    @staticmethod
    def is_valid_channel_id(channel_id: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ YouTube channel ID"""
        if not channel_id:
            return False
        return bool(re.match(r'^UC[a-zA-Z0-9_-]{22}$', channel_id))
    
    @staticmethod
    def is_valid_url(url: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ URL"""
        if not url:
            return False
        
        try:
            result = urllib.parse.urlparse(url)
            return all([result.scheme, result.netloc])
        except Exception:
            return False
    
    @staticmethod
    def is_valid_youtube_url(url: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ YouTube URL"""
        if not ValidationUtils.is_valid_url(url):
            return False
        
        youtube_domains = ['youtube.com', 'youtu.be', 'm.youtube.com', 'www.youtube.com']
        parsed_url = urllib.parse.urlparse(url)
        return parsed_url.netloc.lower() in youtube_domains

# –°–æ–∑–¥–∞—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–µ —ç–∫–∑–µ–º–ø–ª—è—Ä—ã —É—Ç–∏–ª–∏—Ç
file_utils = FileUtils()
validation_utils = ValidationUtils()

# –≠–∫—Å–ø–æ—Ä—Ç –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
format_number = Utils.format_number
format_duration = Utils.format_duration
format_date = Utils.format_date
calculate_engagement_rate = Utils.calculate_engagement_rate
clean_text = Utils.clean_text
extract_keywords = Utils.extract_keywords

print("‚úÖ Utils –∑–∞–≥—Ä—É–∂–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ")