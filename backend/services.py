"""
YouTube Analyzer - Enhanced API Services
–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Å–µ—Ä–≤–∏—Å—ã —Å –∞–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∏ —É–ª—É—á—à–µ–Ω–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º
"""
from fastapi import APIRouter, BackgroundTasks, HTTPException, UploadFile, File
from typing import List, Dict, Optional, Any
import uuid
import asyncio
import json
from datetime import datetime, timedelta
import sys
from pathlib import Path
import re
from collections import Counter
import hashlib

# –î–æ–±–∞–≤–∏—Ç—å –ø—É—Ç–∏ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
current_dir = Path(__file__).parent
project_root = current_dir.parent
sys.path.append(str(project_root))

from models import *
from database import DatabaseManager
from shared.config import settings
from shared.utils import Utils
from shared.youtube_parser import YouTubeParser

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
db = DatabaseManager()
utils = Utils()
youtube_parser = YouTubeParser(settings.YOUTUBE_API_KEY) if settings.YOUTUBE_API_KEY else None

# –°–æ–∑–¥–∞–Ω–∏–µ —Ä–æ—É—Ç–µ—Ä–æ–≤
tasks_router = APIRouter()
youtube_router = APIRouter()
analysis_router = APIRouter()
data_router = APIRouter()
config_router = APIRouter()

# –ì–ª–æ–±–∞–ª—å–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –∑–∞–¥–∞—á
active_tasks = {}

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è –∞–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
AUTOSAVE_INTERVAL = 10  # –°–æ—Ö—Ä–∞–Ω—è—Ç—å –∫–∞–∂–¥—ã–µ 10 –≤–∏–¥–µ–æ
CHECKPOINT_INTERVAL = 300  # –°–æ–∑–¥–∞–≤–∞—Ç—å —á–µ–∫–ø–æ–∏–Ω—Ç –∫–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç

# –ó–∞–≥—Ä—É–∑–∫–∞ –∞–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–¥–∞—á –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
def load_active_tasks():
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –∞–∫—Ç–∏–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏ –∏–∑ –ë–î —Å –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è"""
    global active_tasks
    try:
        tasks = db.get_all_tasks()
        for task in tasks:
            if task['status'] in ['running', 'paused', 'created']:
                active_tasks[task['task_id']] = task
                
                # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —á–µ–∫–ø–æ–∏–Ω—Ç –µ—Å–ª–∏ –µ—Å—Ç—å
                checkpoint = db.get_task_checkpoint(task['task_id'])
                if checkpoint:
                    active_tasks[task['task_id']]['checkpoint'] = checkpoint
                    
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(active_tasks)} –∞–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–¥–∞—á")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∑–∞–¥–∞—á: {e}")

# –ó–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ
load_active_tasks()

# ============ ENHANCED ANALYSIS FUNCTIONS ============

async def analyze_video_extended(video_data: Dict[str, Any]) -> Dict[str, Any]:
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏"""
    
    # –ë–∞–∑–æ–≤—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è
    video_data['title_length'] = len(video_data.get('title', ''))
    video_data['description_length'] = len(video_data.get('description', ''))
    
    # –ê–Ω–∞–ª–∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞
    title = video_data.get('title', '')
    video_data['emoji_in_title'] = utils.has_emoji(title)
    
    # –ü–æ–¥—Å—á–µ—Ç —Ö—ç—à—Ç–µ–≥–æ–≤
    description = video_data.get('description', '')
    video_data['hashtags_count'] = len(re.findall(r'#\w+', description))
    
    # –ü–æ–∏—Å–∫ —É–ø–æ–º—è–Ω—É—Ç—ã—Ö –∫–∞–Ω–∞–ª–æ–≤
    mentioned = re.findall(r'@[\w-]+', description)
    video_data['mentioned_channels'] = mentioned[:10]  # –ú–∞–∫—Å–∏–º—É–º 10
    
    # –ê–Ω–∞–ª–∏–∑ —Å—Å—ã–ª–æ–∫
    video_data['links_in_description'] = utils.count_links(description)
    
    # –ü–æ–∏—Å–∫ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤
    email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
    emails = re.findall(email_pattern, description)
    video_data['contacts_in_video'] = emails[:5]  # –ú–∞–∫—Å–∏–º—É–º 5
    
    # SEO –æ—Ü–µ–Ω–∫–∞ (0-100)
    seo_score = 0
    if video_data.get('tags') and len(video_data['tags']) > 5:
        seo_score += 20
    if video_data['description_length'] > 200:
        seo_score += 20
    if video_data.get('has_cc'):
        seo_score += 20
    if video_data['hashtags_count'] > 0:
        seo_score += 10
    if video_data['title_length'] > 40 and video_data['title_length'] < 70:
        seo_score += 15
    if video_data['emoji_in_title']:
        seo_score += 5
    if video_data.get('thumbnail_url'):
        seo_score += 10
    
    video_data['seo_score'] = min(seo_score, 100)
    
    # –û—Ü–µ–Ω–∫–∞ –∫–ª–∏–∫–∞–±–µ–ª—å–Ω–æ—Å—Ç–∏ –ø—Ä–µ–≤—å—é (0-100)
    thumbnail_score = 50  # –ë–∞–∑–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞
    if video_data['emoji_in_title']:
        thumbnail_score += 10
    if '!' in title or '?' in title:
        thumbnail_score += 10
    if any(word in title.lower() for word in ['—Ç–æ–ø', '–ª—É—á—à–∏–π', '—Å–µ–∫—Ä–µ—Ç', '–±—ã—Å—Ç—Ä–æ', '–ø—Ä–æ—Å—Ç–æ']):
        thumbnail_score += 15
    if video_data.get('is_short'):
        thumbnail_score += 15
    
    video_data['thumbnail_click_score'] = min(thumbnail_score, 100)
    
    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
    categories = {
        'education': ['—É—Ä–æ–∫', 'tutorial', '–æ–±—É—á–µ–Ω–∏–µ', '–≥–∞–π–¥', 'guide', '–∫–∞–∫ —Å–¥–µ–ª–∞—Ç—å'],
        'entertainment': ['–≤–ª–æ–≥', 'vlog', '–ø—Ä–∞–Ω–∫', '—á–µ–ª–ª–µ–Ω–¥–∂', 'challenge', '—Ä–µ–∞–∫—Ü–∏—è'],
        'gaming': ['–∏–≥—Ä–∞', 'game', '–ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–µ', '—Å—Ç—Ä–∏–º', 'stream', '–≥–µ–π–º–ø–ª–µ–π'],
        'tech': ['–æ–±–∑–æ—Ä', 'review', '—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏', '–≥–∞–¥–∂–µ—Ç', '–Ω–æ–≤–∏–Ω–∫–∞', '—Ç–µ—Å—Ç'],
        'music': ['–∫–ª–∏–ø', '–ø–µ—Å–Ω—è', 'music', 'song', '–∫–∞–≤–µ—Ä', 'cover'],
        'news': ['–Ω–æ–≤–æ—Å—Ç–∏', 'news', '—Å–æ–±—ã—Ç–∏—è', 'breaking', '—Å—Ä–æ—á–Ω–æ']
    }
    
    detected_category = 'other'
    title_lower = title.lower()
    for category, keywords in categories.items():
        if any(keyword in title_lower for keyword in keywords):
            detected_category = category
            break
    
    video_data['video_category'] = detected_category
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ —É–ª—É—á—à–µ–Ω–∏—é
    improvements = []
    
    if not video_data.get('has_cc'):
        improvements.append("–î–æ–±–∞–≤—å—Ç–µ —Å—É–±—Ç–∏—Ç—Ä—ã –¥–ª—è —É–≤–µ–ª–∏—á–µ–Ω–∏—è –æ—Ö–≤–∞—Ç–∞")
    
    if video_data['engagement_rate'] < 2:
        improvements.append("–ù–∏–∑–∫–∞—è –≤–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç—å - —É–ª—É—á—à–∏—Ç–µ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ –ø—Ä–µ–≤—å—é")
    
    if video_data['description_length'] < 100:
        improvements.append("–°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ - –¥–æ–±–∞–≤—å—Ç–µ –±–æ–ª—å—à–µ –¥–µ—Ç–∞–ª–µ–π –∏ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤")
    
    if not video_data.get('tags') or len(video_data['tags']) < 5:
        improvements.append("–î–æ–±–∞–≤—å—Ç–µ –±–æ–ª—å—à–µ —Ç–µ–≥–æ–≤ (–º–∏–Ω–∏–º—É–º 10)")
    
    if not video_data['emoji_in_title'] and detected_category in ['entertainment', 'gaming']:
        improvements.append("–î–æ–±–∞–≤—å—Ç–µ —ç–º–æ–¥–∑–∏ –≤ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–ª—è –ø—Ä–∏–≤–ª–µ—á–µ–Ω–∏—è –≤–Ω–∏–º–∞–Ω–∏—è")
    
    if video_data['title_length'] > 70:
        improvements.append("–°–æ–∫—Ä–∞—Ç–∏—Ç–µ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ 60-70 —Å–∏–º–≤–æ–ª–æ–≤")
    
    if video_data['hashtags_count'] == 0:
        improvements.append("–î–æ–±–∞–≤—å—Ç–µ 3-5 —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ö—ç—à—Ç–µ–≥–æ–≤")
    
    video_data['improvement_suggestions'] = improvements[:5]
    
    # –°—Ç—Ä–∞—Ç–µ–≥–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞
    strategy_parts = []
    
    if video_data.get('is_short'):
        strategy_parts.append("Shorts —Ñ–æ—Ä–º–∞—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ - –ø—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ")
    else:
        if video_data.get('duration_seconds', 0) > 600:
            strategy_parts.append("–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ —Å–æ–∑–¥–∞–Ω–∏–µ –∫–æ—Ä–æ—Ç–∫–∏—Ö –≤–µ—Ä—Å–∏–π –¥–ª—è Shorts")
    
    if video_data['engagement_rate'] > 5:
        strategy_parts.append("–í—ã—Å–æ–∫–∞—è –≤–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç—å - –∏–∑—É—á–∏—Ç–µ –∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ —É—Å–ø–µ—à–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã")
    
    if detected_category == 'education':
        strategy_parts.append("–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç - —Å–æ–∑–¥–∞–π—Ç–µ —Å–µ—Ä–∏—é —É—Ä–æ–∫–æ–≤")
    
    video_data['content_strategy'] = '. '.join(strategy_parts)
    
    # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –¥–æ—Ö–æ–¥–∞ (–æ—á–µ–Ω—å –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ)
    if video_data.get('views', 0) > 0:
        # $1-3 –∑–∞ 1000 –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ –≤ —Å—Ä–µ–¥–Ω–µ–º
        cpm = 2.0  # –°—Ä–µ–¥–Ω–∏–π CPM
        if detected_category in ['education', 'tech']:
            cpm = 3.0
        elif detected_category in ['gaming', 'entertainment']:
            cpm = 1.5
        
        estimated_revenue = (video_data['views'] / 1000) * cpm
        video_data['estimated_revenue'] = round(estimated_revenue, 2)
    
    return video_data

async def analyze_channel_extended(channel_data: Dict[str, Any]) -> Dict[str, Any]:
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–∞–Ω–∞–ª–∞"""
    
    channel_id = channel_data['channel_id']
    
    # –í—ã—á–∏—Å–ª–∏—Ç—å —á–∞—Å—Ç–æ—Ç—É –∑–∞–≥—Ä—É–∑–æ–∫
    upload_frequency = db.get_channel_upload_frequency(channel_id)
    channel_data['upload_frequency'] = round(upload_frequency, 2)
    
    # –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø –∫–∞–Ω–∞–ª–∞
    if channel_data.get('video_count', 0) > 100:
        channel_data['channel_type'] = 'media'
    elif channel_data.get('subscriber_count', 0) > 100000:
        channel_data['channel_type'] = 'brand'
    else:
        channel_data['channel_type'] = 'personal'
    
    # –û—Ü–µ–Ω–∫–∞ —Ä–æ—Å—Ç–∞ (–ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ)
    if upload_frequency > 0:
        # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º —Ä–æ—Å—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ —á–∞—Å—Ç–æ—Ç—ã –∑–∞–≥—Ä—É–∑–æ–∫ –∏ –≤–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç–∏
        growth_factor = upload_frequency * 0.1
        if channel_data.get('avg_engagement_rate', 0) > 5:
            growth_factor *= 1.5
        channel_data['growth_rate'] = round(growth_factor, 2)
    
    # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –º–µ—Å—è—á–Ω–æ–≥–æ –¥–æ—Ö–æ–¥–∞
    if channel_data.get('avg_views', 0) > 0 and upload_frequency > 0:
        monthly_views = channel_data['avg_views'] * upload_frequency
        cpm = 2.0  # –°—Ä–µ–¥–Ω–∏–π CPM
        channel_data['estimated_monthly_revenue'] = round((monthly_views / 1000) * cpm, 2)
    
    return channel_data

# ============ TASKS SERVICE WITH CHECKPOINTS ============

@tasks_router.get("/", response_model=List[Dict])
async def get_tasks():
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∑–∞–¥–∞—á"""
    try:
        tasks = db.get_all_tasks()
        return tasks
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∑–∞–¥–∞—á: {str(e)}")

@tasks_router.get("/active")
async def get_active_tasks():
    """–ü–æ–ª—É—á–∏—Ç—å –∞–∫—Ç–∏–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏ –≤ –ø–∞–º—è—Ç–∏"""
    return {
        "count": len(active_tasks),
        "tasks": list(active_tasks.values())
    }

@tasks_router.post("/", response_model=TaskCreateResponse)
async def create_task(task: TaskCreate, background_tasks: BackgroundTasks):
    """–°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—É—é –∑–∞–¥–∞—á—É –∞–Ω–∞–ª–∏–∑–∞"""
    try:
        # –í–∞–ª–∏–¥–∞—Ü–∏—è
        if not task.keywords and not task.channels:
            raise HTTPException(status_code=400, detail="–£–∫–∞–∂–∏—Ç–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–ª–∏ –∫–∞–Ω–∞–ª—ã")
        
        if not youtube_parser:
            raise HTTPException(status_code=400, detail="YouTube API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏
        task_id = str(uuid.uuid4())
        total_items = len(task.keywords) + len(task.channels)
        
        task_data = {
            "task_id": task_id,
            "status": "created",
            "progress": 0,
            "total_items": total_items,
            "created_at": datetime.now().isoformat(),
            "config": task.dict(),
            "items_processed": [],
            "items_failed": []
        }
        
        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –ë–î
        db.save_task(task_data)
        active_tasks[task_id] = task_data
        
        # –ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É –≤ —Ñ–æ–Ω–µ
        background_tasks.add_task(process_task_with_checkpoints, task_id, task)
        
        return TaskCreateResponse(
            task_id=task_id,
            status=TaskStatus.CREATED,
            message="–ó–∞–¥–∞—á–∞ —Å–æ–∑–¥–∞–Ω–∞ –∏ –∑–∞–ø—É—â–µ–Ω–∞"
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞–¥–∞—á–∏: {str(e)}")

@tasks_router.get("/{task_id}")
async def get_task(task_id: str):
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∑–∞–¥–∞—á–∏"""
    try:
        task = db.get_task(task_id)
        if not task:
            raise HTTPException(status_code=404, detail="–ó–∞–¥–∞—á–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return task
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∑–∞–¥–∞—á–∏: {str(e)}")

@tasks_router.post("/{task_id}/pause")
async def pause_task(task_id: str):
    """–ü–æ—Å—Ç–∞–≤–∏—Ç—å –∑–∞–¥–∞—á—É –Ω–∞ –ø–∞—É–∑—É —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è"""
    try:
        if task_id in active_tasks:
            # –°–æ–∑–¥–∞—Ç—å —á–µ–∫–ø–æ–∏–Ω—Ç –ø–µ—Ä–µ–¥ –ø–∞—É–∑–æ–π
            checkpoint_data = {
                'status': 'paused',
                'progress': active_tasks[task_id].get('progress', 0),
                'timestamp': datetime.now().isoformat(),
                'active_items': active_tasks[task_id].get('active_items', [])
            }
            
            db.save_task_checkpoint(task_id, checkpoint_data)
            
            active_tasks[task_id]["status"] = "paused"
            db.update_task_status(task_id, "paused")
            
            return {"message": "–ó–∞–¥–∞—á–∞ –ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∞ –Ω–∞ –ø–∞—É–∑—É", "status": "paused"}
        
        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –≤ –ë–î
        task = db.get_task(task_id)
        if task and task['status'] == 'running':
            db.update_task_status(task_id, "paused")
            return {"message": "–ó–∞–¥–∞—á–∞ –ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∞ –Ω–∞ –ø–∞—É–∑—É", "status": "paused"}
            
        raise HTTPException(status_code=404, detail="–ê–∫—Ç–∏–≤–Ω–∞—è –∑–∞–¥–∞—á–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø–∞—É–∑—ã –∑–∞–¥–∞—á–∏: {str(e)}")

@tasks_router.post("/{task_id}/resume")
async def resume_task(task_id: str, background_tasks: BackgroundTasks):
    """–í–æ–∑–æ–±–Ω–æ–≤–∏—Ç—å –∑–∞–¥–∞—á—É —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —á–µ–∫–ø–æ–∏–Ω—Ç–∞"""
    try:
        task = db.get_task(task_id)
        if not task:
            raise HTTPException(status_code=404, detail="–ó–∞–¥–∞—á–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        
        if task['status'] == 'paused':
            # –ü–æ–ª—É—á–∏—Ç—å —á–µ–∫–ø–æ–∏–Ω—Ç
            checkpoint = db.get_task_checkpoint(task_id)
            
            # –û–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å
            db.update_task_status(task_id, "running")
            active_tasks[task_id] = task
            active_tasks[task_id]["status"] = "running"
            
            if checkpoint:
                active_tasks[task_id]["checkpoint"] = checkpoint
            
            # –í–æ–∑–æ–±–Ω–æ–≤–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É
            task_config = json.loads(task['config']) if isinstance(task['config'], str) else task['config']
            task_obj = TaskCreate(**task_config)
            background_tasks.add_task(process_task_with_checkpoints, task_id, task_obj, resume=True)
            
            return {"message": "–ó–∞–¥–∞—á–∞ –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∞", "status": "running"}
        else:
            raise HTTPException(status_code=400, detail=f"–ó–∞–¥–∞—á–∞ –Ω–µ –Ω–∞ –ø–∞—É–∑–µ, —Ç–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å: {task['status']}")
            
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∑–∞–¥–∞—á–∏: {str(e)}")

async def process_task_with_checkpoints(task_id: str, task: TaskCreate, resume: bool = False):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–¥–∞—á–∏ —Å –∞–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∏ —á–µ–∫–ø–æ–∏–Ω—Ç–∞–º–∏"""
    try:
        print(f"üîÑ {'–í–æ–∑–æ–±–Ω–æ–≤–ª—è–µ–º' if resume else '–ù–∞—á–∏–Ω–∞–µ–º'} –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–¥–∞—á–∏ {task_id}")
        
        if not resume:
            active_tasks[task_id]["status"] = "running"
            db.update_task_status(task_id, "running")
        
        # –ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å
        current_task = db.get_task(task_id)
        checkpoint = db.get_task_checkpoint(task_id) if resume else None
        

    except Exception as e:
        print(f'–û—à–∏–±–∫–∞: {e}')
        pass
items_processed_data = current_task.get('items_processed', '[]')
items_failed_data = current_task.get('items_failed', '[]')

# –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–¥ –ø–∞—Ä—Å–∏–Ω–≥–æ–º
if isinstance(items_processed_data, str):
    processed_items = set(json.loads(items_processed_data))
elif isinstance(items_processed_data, list):
    processed_items = set(items_processed_data)
else:
    processed_items = set()

if isinstance(items_failed_data, str):
    failed_items = set(json.loads(items_failed_data))
elif isinstance(items_failed_data, list):
    failed_items = set(items_failed_data)
else:
    failed_items = set()

      
        # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å –∏–∑ —á–µ–∫–ø–æ–∏–Ω—Ç–∞
        if checkpoint and 'processed_items' in checkpoint:
            processed_items.update(checkpoint['processed_items'])
        
        total = len(task.keywords) + len(task.channels)
        last_checkpoint_time = datetime.now()
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        for idx, keyword in enumerate(task.keywords):
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ
            item_id = f"keyword:{keyword}"
            if item_id in processed_items:
                continue
                
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞—É–∑—ã
            if task_id in active_tasks and active_tasks[task_id]["status"] == "paused":
                print(f"‚è∏Ô∏è  –ó–∞–¥–∞—á–∞ {task_id} –Ω–∞ –ø–∞—É–∑–µ")
                return
                
            print(f"üîç –ü–æ–∏—Å–∫ –≤–∏–¥–µ–æ –ø–æ –∑–∞–ø—Ä–æ—Å—É: {keyword}")
            try:
                videos = youtube_parser.search_videos(
                    keyword, 
                    settings.MAX_LONG_VIDEOS_SEARCH + settings.MAX_SHORTS_SEARCH,
                    task.order_by.value
                )
                
                await process_videos_extended(videos, task_id)
                
                # –û—Ç–º–µ—Ç–∏—Ç—å –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π
                processed_items.add(item_id)
                
                # –û–±–Ω–æ–≤–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å
                progress = len(processed_items)
                active_tasks[task_id]["progress"] = progress
                
                # –ê–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
                if len(processed_items) % AUTOSAVE_INTERVAL == 0:
                    db.update_task_progress_extended(
                        task_id, progress, total,
                        list(processed_items), list(failed_items)
                    )
                
                # –ß–µ–∫–ø–æ–∏–Ω—Ç –∫–∞–∂–¥—ã–µ N –º–∏–Ω—É—Ç
                if (datetime.now() - last_checkpoint_time).seconds > CHECKPOINT_INTERVAL:
                    checkpoint_data = {
                        'processed_items': list(processed_items),
                        'failed_items': list(failed_items),
                        'current_keyword': keyword,
                        'progress': progress
                    }
                    db.save_task_checkpoint(task_id, checkpoint_data)
                    last_checkpoint_time = datetime.now()
                
                await asyncio.sleep(settings.REQUEST_DELAY)
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–ª—é—á–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞ {keyword}: {e}")
                failed_items.add(item_id)
                continue
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–Ω–∞–ª–æ–≤
        for idx, channel_url in enumerate(task.channels):
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ
            item_id = f"channel:{channel_url}"
            if item_id in processed_items:
                continue
                
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞—É–∑—ã
            if task_id in active_tasks and active_tasks[task_id]["status"] == "paused":
                print(f"‚è∏Ô∏è  –ó–∞–¥–∞—á–∞ {task_id} –Ω–∞ –ø–∞—É–∑–µ")
                return
                
            print(f"üì∫ –ê–Ω–∞–ª–∏–∑ –∫–∞–Ω–∞–ª–∞: {channel_url}")
            try:
                channel_id = youtube_parser.extract_channel_id(channel_url)
                if channel_id:
                    # –ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–∞–Ω–∞–ª–µ
                    channel_info = youtube_parser.get_channel_info(channel_id)
                    if channel_info:
                        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–∞–Ω–∞–ª–∞
                        channel_info = await analyze_channel_extended(channel_info)
                        db.save_channel(channel_info)
                    
                    # –ü–æ–ª—É—á–∏—Ç—å –≤–∏–¥–µ–æ –∫–∞–Ω–∞–ª–∞
                    videos = youtube_parser.get_channel_videos(
                        channel_id, 
                        settings.MAX_LONG_VIDEOS_CHANNEL + settings.MAX_SHORTS_CHANNEL
                    )
                    await process_videos_extended(videos, task_id)
                
                # –û—Ç–º–µ—Ç–∏—Ç—å –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π
                processed_items.add(item_id)
                
                # –û–±–Ω–æ–≤–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å
                progress = len(processed_items)
                active_tasks[task_id]["progress"] = progress
                
                # –ê–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
                if len(processed_items) % AUTOSAVE_INTERVAL == 0:
                    db.update_task_progress_extended(
                        task_id, progress, total,
                        list(processed_items), list(failed_items)
                    )
                
                await asyncio.sleep(settings.REQUEST_DELAY)
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞–Ω–∞–ª–∞ {channel_url}: {e}")
                failed_items.add(item_id)
                continue
        
        # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        db.update_task_progress_extended(
            task_id, len(processed_items), total,
            list(processed_items), list(failed_items)
        )
        
        # –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏
        active_tasks[task_id]["status"] = "completed"
        db.update_task_status(task_id, "completed")
        
        # –£–¥–∞–ª–∏—Ç—å –∏–∑ –∞–∫—Ç–∏–≤–Ω—ã—Ö
        if task_id in active_tasks:
            del active_tasks[task_id]
            
        print(f"‚úÖ –ó–∞–¥–∞—á–∞ {task_id} –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
        
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –∑–∞–¥–∞—á–µ {task_id}: {e}")
        if task_id in active_tasks:
            active_tasks[task_id]["status"] = "error"
        db.update_task_status(task_id, "error", str(e))

async def process_videos_extended(videos: List[Dict], task_id: str):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º –∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
    for video in videos:
        try:
            video_id = video.get('video_id')
            if not video_id or db.video_exists(video_id):
                continue
            
            print(f"  üìπ –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ: {video.get('title', 'Unknown')[:50]}...")
            
            # –ü–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–∏–¥–µ–æ
            details = youtube_parser.get_video_details([video_id])
            if video_id in details:
                video.update(details[video_id])
            
            # –î–æ–±–∞–≤–∏—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            video['analyzed_at'] = datetime.now().isoformat()
            video['task_id'] = task_id
            
            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫—ç—à —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–æ–≤
            cached_transcript = db.get_cached_transcript(video_id)
            
            if cached_transcript:
                video['transcript'] = cached_transcript['transcript']
                video['transcript_source'] = f"cache_{cached_transcript['source']}"
                print(f"    ‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç –∑–∞–≥—Ä—É–∂–µ–Ω –∏–∑ –∫—ç—à–∞")
            else:
                # –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç
                try:
                    from youtube_transcript_api import YouTubeTranscriptApi
                    
                    # –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –ø–æ–ª—É—á–∏—Ç—å —Å—É–±—Ç–∏—Ç—Ä—ã
                    transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)
                    
                    # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: —Ä—É—Å—Å–∫–∏–µ -> –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ -> –ª—é–±—ã–µ
                    transcript = None
                    try:
                        transcript = transcript_list.find_transcript(['ru'])
                    except:
                        try:
                            transcript = transcript_list.find_transcript(['en'])
                        except:
                            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –¥–æ—Å—Ç—É–ø–Ω—ã–π
                            for t in transcript_list:
                                transcript = t
                                break
                    
                    if transcript:
                        transcript_text = ' '.join([entry['text'] for entry in transcript.fetch()])
                        video['transcript'] = transcript_text[:50000]  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª–∏–Ω—ã
                        video['transcript_source'] = f"youtube_{transcript.language_code}"
                        print(f"    ‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç –ø–æ–ª—É—á–µ–Ω ({transcript.language_code})")
                        
                        # –ö—ç—à–∏—Ä–æ–≤–∞—Ç—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç
                        db.cache_transcript(
                            video_id, 
                            transcript_text, 
                            transcript.language_code,
                            'youtube'
                        )
                        
                except Exception as e:
                    print(f"    ‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç: {e}")
                    video['transcript_source'] = 'none'
            
            # –ê–Ω–∞–ª–∏–∑ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞ –µ—Å–ª–∏ –µ—Å—Ç—å
            if video.get('transcript'):
                transcript_text = video['transcript']
                
                # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
                video['keywords'] = utils.extract_keywords(transcript_text, top_n=10)
                video['top_5_keywords'] = video['keywords'][:5]
                
                # –ê–Ω–∞–ª–∏–∑ —Å–∫–æ—Ä–æ—Å—Ç–∏ —Ä–µ—á–∏ (—Å–ª–æ–≤ –≤ –º–∏–Ω—É—Ç—É)
                word_count = len(transcript_text.split())
                duration_seconds = video.get('duration_seconds', 0)
                if duration_seconds > 0:
                    video['speech_speed'] = round((word_count / duration_seconds) * 60, 1)
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ä–µ–∫–ª–∞–º—É
                ad_keywords = ['—Å–ø–æ–Ω—Å–æ—Ä', '—Ä–µ–∫–ª–∞–º–∞', '–ø—Ä–æ–º–æ–∫–æ–¥', '—Å–∫–∏–¥–∫–∞', 'sponsor', 'promo', 'discount']
                video['has_branding'] = any(keyword in transcript_text.lower() for keyword in ad_keywords)
                
                # –ê–Ω–∞–ª–∏–∑ –∏–Ω—Ç—Ä–æ/–∞—É—Ç—Ä–æ
                if duration_seconds > 30:
                    # –ü–µ—Ä–≤—ã–µ 10% —Ç–µ–∫—Å—Ç–∞
                    intro_text = transcript_text[:len(transcript_text)//10]
                    # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10% —Ç–µ–∫—Å—Ç–∞
                    outro_text = transcript_text[-len(transcript_text)//10:]
                    
                    intro_patterns = ['–ø—Ä–∏–≤–µ—Ç', '–¥–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å', 'hello', 'welcome', '–≤—Å–µ–º –ø—Ä–∏–≤–µ—Ç']
                    outro_patterns = ['–ø–æ–¥–ø–∏—Å—ã–≤–∞–π—Ç–µ—Å—å', '–ª–∞–π–∫', 'subscribe', 'like', '–ø–æ–∫–∞', '—É–≤–∏–¥–∏–º—Å—è']
                    
                    video['has_intro'] = any(pattern in intro_text.lower() for pattern in intro_patterns)
                    video['has_outro'] = any(pattern in outro_text.lower() for pattern in outro_patterns)
            
            # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –≤–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç–∏
            views = video.get('views', 0)
            likes = video.get('likes', 0)
            comments = video.get('comments', 0)
            
            if views > 0:
                video['like_ratio'] = utils.calculate_like_ratio(views, likes)
                video['comment_ratio'] = utils.calculate_comment_ratio(views, comments)
                video['engagement_rate'] = utils.calculate_engagement_rate(views, likes, comments)
            else:
                video['like_ratio'] = 0
                video['comment_ratio'] = 0
                video['engagement_rate'] = 0
            
            # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑
            video = await analyze_video_extended(video)
            
            # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –ë–î
            db.save_video(video)
            print(f"    ‚úÖ –í–∏–¥–µ–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ –ë–î")
            
            # –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
            if video.get('keywords'):
                for keyword in video['keywords'][:3]:  # –¢–æ–ø 3 –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤–∞
                    trend_data = {
                        'video_count': 1,
                        'avg_views': views,
                        'avg_engagement': video['engagement_rate'],
                        'top_channels': [video.get('channel_title', '')],
                        'trending_topics': video.get('tags', [])[:5]
                    }
                    db.save_trend_analysis(keyword, trend_data)
            
        except Exception as e:
            print(f"  ‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ {video.get('video_id', 'unknown')}: {e}")
            continue

# ============ YOUTUBE SERVICE ============

@youtube_router.get("/search")
async def search_videos(query: str, max_results: int = 10, order: str = "relevance"):
    """–ü–æ–∏—Å–∫ –≤–∏–¥–µ–æ –ø–æ –∑–∞–ø—Ä–æ—Å—É"""
    try:
        if not youtube_parser:
            raise HTTPException(status_code=400, detail="YouTube API –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
        
        videos = youtube_parser.search_videos(query, max_results, order)
        
        # –ü–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        video_ids = [v['video_id'] for v in videos]
        details = youtube_parser.get_video_details(video_ids)
        
        # –û–±—ä–µ–¥–∏–Ω–∏—Ç—å –¥–∞–Ω–Ω—ã–µ
        for video in videos:
            if video['video_id'] in details:
                video.update(details[video['video_id']])
        
        return {
            "videos": videos, 
            "count": len(videos),
            "query": query,
            "order": order
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {str(e)}")

@youtube_router.get("/channel/{channel_id}")
async def get_channel_info(channel_id: str):
    """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–∞–Ω–∞–ª–µ"""
    try:
        if not youtube_parser:
            raise HTTPException(status_code=400, detail="YouTube API –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
        
        channel_info = youtube_parser.get_channel_info(channel_id)
        if not channel_info:
            raise HTTPException(status_code=404, detail="–ö–∞–Ω–∞–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        channel_info = await analyze_channel_extended(channel_info)
        
        return channel_info
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–∞–Ω–∞–ª–∞: {str(e)}")

@youtube_router.get("/channel/{channel_id}/videos")
async def get_channel_videos(channel_id: str, max_results: int = 20):
    """–ü–æ–ª—É—á–∏—Ç—å –≤–∏–¥–µ–æ –∫–∞–Ω–∞–ª–∞"""
    try:
        if not youtube_parser:
            raise HTTPException(status_code=400, detail="YouTube API –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
        
        videos = youtube_parser.get_channel_videos(channel_id, max_results)
        
        # –ü–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        video_ids = [v['video_id'] for v in videos]
        details = youtube_parser.get_video_details(video_ids)
        
        # –û–±—ä–µ–¥–∏–Ω–∏—Ç—å –¥–∞–Ω–Ω—ã–µ
        for video in videos:
            if video['video_id'] in details:
                video.update(details[video['video_id']])
        
        return {
            "channel_id": channel_id,
            "videos": videos,
            "count": len(videos)
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –≤–∏–¥–µ–æ –∫–∞–Ω–∞–ª–∞: {str(e)}")

# ============ DATA SERVICE ============

@data_router.get("/videos")
async def get_videos(
    limit: int = 100, 
    offset: int = 0,
    is_short: Optional[bool] = None,
    channel_id: Optional[str] = None,
    min_views: Optional[int] = None,
    min_engagement: Optional[float] = None
):
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≤–∏–¥–µ–æ —Å —Ñ–∏–ª—å—Ç—Ä–∞–º–∏"""
    try:
        filters = {}
        if is_short is not None:
            filters['is_short'] = is_short
        if channel_id:
            filters['channel_id'] = channel_id
        if min_views:
            filters['min_views'] = min_views
        if min_engagement:
            filters['min_engagement'] = min_engagement
        
        videos = db.get_videos(limit, offset, filters)
        return videos
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –≤–∏–¥–µ–æ: {str(e)}")

@data_router.get("/videos/{video_id}")
async def get_video_details(video_id: str):
    """–ü–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–∏–¥–µ–æ"""
    try:
        video = db.get_video_by_id(video_id)
        if not video:
            raise HTTPException(status_code=404, detail="–í–∏–¥–µ–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        return video
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –≤–∏–¥–µ–æ: {str(e)}")

@data_router.get("/channels")
async def get_channels():
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤"""
    try:
        channels = db.get_channels()
        return channels
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–∞–Ω–∞–ª–æ–≤: {str(e)}")

@data_router.get("/channels/{channel_id}")
async def get_channel_details(channel_id: str):
    """–ü–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–∞–Ω–∞–ª–µ"""
    try:
        channel = db.get_channel_stats(channel_id)
        if not channel:
            raise HTTPException(status_code=404, detail="–ö–∞–Ω–∞–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return channel
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–∞–Ω–∞–ª–∞: {str(e)}")

@data_router.get("/stats")
async def get_statistics():
    """–ü–æ–ª—É—á–∏—Ç—å –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
    try:
        stats = db.get_statistics()
        stats['active_tasks'] = len(active_tasks)
        
        # –û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–µ–∫—à–∏–π –∫—ç—à
        db.clean_expired_cache()
        
        return stats
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {str(e)}")

@data_router.get("/export")
async def export_to_excel():
    """–≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –≤ Excel"""
    try:
        filename = db.export_to_excel()
        file_path = Path(filename)
        
        return {
            "filename": file_path.name,
            "status": "exported",
            "path": str(file_path),
            "size": file_path.stat().st_size if file_path.exists() else 0
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞: {str(e)}")

@data_router.get("/export/download/{filename}")
async def download_export(filename: str):
    """–°–∫–∞—á–∞—Ç—å —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–∞–π–ª"""
    from fastapi.responses import FileResponse
    
    file_path = Path(settings.EXPORT_DIR) / filename
    if file_path.exists() and file_path.suffix == '.xlsx':
        return FileResponse(
            path=str(file_path),
            filename=filename,
            media_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
        )
    raise HTTPException(status_code=404, detail="–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")

@data_router.delete("/clear")
async def clear_database():
    """–û—á–∏—Å—Ç–∏—Ç—å –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
    try:
        # –û—á–∏—Å—Ç–∏—Ç—å –∞–∫—Ç–∏–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏
        active_tasks.clear()
        
        # –û—á–∏—Å—Ç–∏—Ç—å –ë–î
        db.clear_database()
        
        return {"message": "–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –æ—á–∏—â–µ–Ω–∞", "status": "success"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –ë–î: {str(e)}")

@data_router.post("/backup")
async def backup_database():
    """–°–æ–∑–¥–∞—Ç—å —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    try:
        backup_path = db.backup_database()
        return {
            "message": "–†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è —Å–æ–∑–¥–∞–Ω–∞",
            "path": backup_path,
            "status": "success"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏: {str(e)}")

# ============ CONFIG SERVICE ============

@config_router.get("/")
async def get_config():
    """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é"""
    try:
        config = settings.get_safe_dict()
        config['has_youtube_api'] = bool(settings.YOUTUBE_API_KEY)
        config['whisper_models'] = ['tiny', 'base', 'small', 'medium', 'large']
        return config
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {str(e)}")

@config_router.post("/")
async def update_config(config_data: dict):
    """–û–±–Ω–æ–≤–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é"""
    try:
        # –û–±–Ω–æ–≤–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        settings.update_from_dict(config_data)
        
        # –ü–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å YouTube parser –µ—Å–ª–∏ –∏–∑–º–µ–Ω–∏–ª—Å—è API –∫–ª—é—á
        global youtube_parser
        if 'youtube_api_key' in config_data and config_data['youtube_api_key']:
            if config_data['youtube_api_key'] != '***':  # –ù–µ –æ–±–Ω–æ–≤–ª—è—Ç—å –µ—Å–ª–∏ —Å–∫—Ä—ã—Ç–æ
                settings.YOUTUBE_API_KEY = config_data['youtube_api_key']
                youtube_parser = YouTubeParser(config_data['youtube_api_key'])
        
        return {
            "message": "–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–∞",
            "status": "success",
            "config": settings.get_safe_dict()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {str(e)}")

@config_router.post("/validate-api-key")
async def validate_api_key(api_key: str):
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å YouTube API –∫–ª—é—á"""
    try:
        # –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —Å–æ–∑–¥–∞—Ç—å –ø–∞—Ä—Å–µ—Ä –∏ —Å–¥–µ–ª–∞—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        test_parser = YouTubeParser(api_key)
        test_videos = test_parser.search_videos("test", 1)
        
        return {
            "valid": True,
            "message": "API –∫–ª—é—á –≤–∞–ª–∏–¥–Ω—ã–π"
        }
    except Exception as e:
        return {
            "valid": False,
            "message": f"–û—à–∏–±–∫–∞ API –∫–ª—é—á–∞: {str(e)}"
        }

# ============ ANALYSIS SERVICE ============

@analysis_router.post("/video/{video_id}")
async def analyze_video(video_id: str):
    """–ü—Ä–æ–≤–µ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –≤–∏–¥–µ–æ"""
    try:
        if not youtube_parser:
            raise HTTPException(status_code=400, detail="YouTube API –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
        
        # –ü–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –≤–∏–¥–µ–æ
        details = youtube_parser.get_video_details([video_id])
        if video_id not in details:
            raise HTTPException(status_code=404, detail="–í–∏–¥–µ–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        
        video_data = details[video_id]
        
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        video_data = await analyze_video_extended(video_data)
        
        # –ü—Ä–æ–≤–µ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑
        analysis_result = {
            "video_id": video_id,
            "engagement_metrics": {
                "views": video_data.get('views', 0),
                "likes": video_data.get('likes', 0),
                "comments": video_data.get('comments', 0),
                "engagement_rate": video_data.get('engagement_rate', 0),
                "like_ratio": video_data.get('like_ratio', 0),
                "comment_ratio": video_data.get('comment_ratio', 0)
            },
            "content_analysis": {
                "duration": video_data.get('duration'),
                "is_short": video_data.get('is_short', False),
                "has_cc": video_data.get('has_cc', False),
                "tags_count": len(video_data.get('tags', [])),
                "video_quality": video_data.get('video_quality', 'sd'),
                "category": video_data.get('video_category', 'other'),
                "seo_score": video_data.get('seo_score', 0),
                "thumbnail_score": video_data.get('thumbnail_click_score', 0)
            },
            "recommendations": video_data.get('improvement_suggestions', []),
            "strategy": video_data.get('content_strategy', ''),
            "estimated_revenue": video_data.get('estimated_revenue', 0),
            "analysis_date": datetime.now().isoformat()
        }
        
        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –ë–î –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        if not db.video_exists(video_id):
            video_data['analyzed_at'] = datetime.now().isoformat()
            db.save_video(video_data)
        
        return analysis_result
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –≤–∏–¥–µ–æ: {str(e)}")

@analysis_router.post("/bulk")
async def analyze_bulk(video_urls: List[str], background_tasks: BackgroundTasks):
    """–ú–∞—Å—Å–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ"""
    try:
        if not youtube_parser:
            raise HTTPException(status_code=400, detail="YouTube API –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
        
        # –ò–∑–≤–ª–µ—á—å video_ids
        video_ids = []
        for url in video_urls:
            video_id = utils.extract_video_id_from_url(url)
            if video_id:
                video_ids.append(video_id)
        
        if not video_ids:
            raise HTTPException(status_code=400, detail="–ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤–∞–ª–∏–¥–Ω—ã—Ö video ID")
        
        # –°–æ–∑–¥–∞—Ç—å –∑–∞–¥–∞—á—É –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        task_id = str(uuid.uuid4())
        task_data = {
            "task_id": task_id,
            "task_type": "bulk_analysis",
            "status": "created",
            "progress": 0,
            "total_items": len(video_ids),
            "config": {"video_ids": video_ids}
        }
        
        db.save_task(task_data)
        active_tasks[task_id] = task_data
        
        # –ó–∞–ø—É—Å—Ç–∏—Ç—å –∞–Ω–∞–ª–∏–∑ –≤ —Ñ–æ–Ω–µ
        background_tasks.add_task(process_bulk_analysis, task_id, video_ids)
        
        return {
            "task_id": task_id,
            "video_count": len(video_ids),
            "status": "started"
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –º–∞—Å—Å–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}")

@analysis_router.get("/competitors/{channel_id}")
async def analyze_competitors(channel_id: str, competitor_ids: List[str] = None):
    """–ê–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ –∫–∞–Ω–∞–ª–∞"""
    try:
        if not competitor_ids:
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞–π—Ç–∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ (–∫–∞–Ω–∞–ª—ã —Å –ø–æ—Ö–æ–∂–∏–º –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º)
            # –≠—Ç–æ —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è - –≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–µ–Ω –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º
            channel_videos = db.get_videos(limit=10, offset=0, filters={'channel_id': channel_id})
            
            if channel_videos:
                # –ü–æ–ª—É—á–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –≤–∏–¥–µ–æ –∫–∞–Ω–∞–ª–∞
                all_keywords = []
                for video in channel_videos:
                    if video.get('keywords'):
                        all_keywords.extend(video['keywords'][:3])
                
                # –ù–∞–π—Ç–∏ –∫–∞–Ω–∞–ª—ã —Å –ø–æ—Ö–æ–∂–∏–º–∏ –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
                # –≠—Ç–æ –∑–∞–≥–ª—É—à–∫–∞ - –Ω—É–∂–Ω–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–∏—Å–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö –∫–∞–Ω–∞–ª–æ–≤
                competitor_ids = []
        
        if not competitor_ids:
            raise HTTPException(status_code=400, detail="–ù–µ –Ω–∞–π–¥–µ–Ω—ã –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        
        # –ü—Ä–æ–≤–µ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑
        analysis = db.analyze_competitor_channels(channel_id, competitor_ids)
        
        return analysis
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤: {str(e)}")

async def process_bulk_analysis(task_id: str, video_ids: List[str]):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –º–∞—Å—Å–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
    try:
        active_tasks[task_id]["status"] = "running"
        db.update_task_status(task_id, "running")
        
        processed = []
        failed = []
        
        for idx, video_id in enumerate(video_ids):
            if task_id in active_tasks and active_tasks[task_id]["status"] == "paused":
                return
            
            try:
                # –ü–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª–∏ –≤–∏–¥–µ–æ
                details = youtube_parser.get_video_details([video_id])
                if video_id in details:
                    video_data = details[video_id]
                    
                    # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑
                    video_data = await analyze_video_extended(video_data)
                    
                    video_data['analyzed_at'] = datetime.now().isoformat()
                    video_data['task_id'] = task_id
                    
                    # –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç
                    await process_videos_extended([video_data], task_id)
                    
                    processed.append(video_id)
                else:
                    failed.append(video_id)
                
                # –û–±–Ω–æ–≤–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å
                progress = idx + 1
                active_tasks[task_id]["progress"] = progress
                db.update_task_progress_extended(task_id, progress, len(video_ids), processed, failed)
                
                await asyncio.sleep(settings.REQUEST_DELAY)
                
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –≤–∏–¥–µ–æ {video_id}: {e}")
                failed.append(video_id)
                continue
        
        # –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ
        active_tasks[task_id]["status"] = "completed"
        db.update_task_status(task_id, "completed")
        
        if task_id in active_tasks:
            del active_tasks[task_id]
        
    except Exception as e:
        active_tasks[task_id]["status"] = "error"
        db.update_task_status(task_id, "error", str(e))

# ============ STARTUP/SHUTDOWN ============

async def startup_event():
    """–î–µ–π—Å—Ç–≤–∏—è –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    print("üöÄ –ó–∞–ø—É—Å–∫ YouTube Analyzer...")
    
    # –ú–∏–≥—Ä–∞—Ü–∏—è –ë–î
    try:
        db.migrate_database()
    except Exception as e:
        print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –º–∏–≥—Ä–∞—Ü–∏–∏ –ë–î: {e}")
    
    # –û—á–∏—Å—Ç–∫–∞ –∏—Å—Ç–µ–∫—à–µ–≥–æ –∫—ç—à–∞
    try:
        db.clean_expired_cache()
    except Exception as e:
        print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –∫—ç—à–∞: {e}")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∞–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–¥–∞—á
    load_active_tasks()
    
    print("‚úÖ –°–µ—Ä–≤–∏—Å—ã –≥–æ—Ç–æ–≤—ã –∫ —Ä–∞–±–æ—Ç–µ")

async def shutdown_event():
    """–î–µ–π—Å—Ç–≤–∏—è –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    print("üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ YouTube Analyzer...")
    
    # –°–æ–∑–¥–∞—Ç—å —á–µ–∫–ø–æ–∏–Ω—Ç—ã –¥–ª—è –≤—Å–µ—Ö –∞–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–¥–∞—á
    for task_id, task in active_tasks.items():
        if task['status'] == 'running':
            checkpoint_data = {
                'status': 'interrupted',
                'progress': task.get('progress', 0),
                'timestamp': datetime.now().isoformat()
            }
            db.save_task_checkpoint(task_id, checkpoint_data)
            db.update_task_status(task_id, 'paused')
    
    print("‚úÖ –°–µ—Ä–≤–∏—Å—ã –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã")

print("‚úÖ Enhanced Services –∑–∞–≥—Ä—É–∂–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ")